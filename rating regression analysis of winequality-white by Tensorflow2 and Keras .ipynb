{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rating regression analysis of winequality-white \n",
    "Winequality-white is a dataset consisting of 11 features and the quality. The features are the levels of chemical ingredients in the wine, which may influence the taste of the wine. Aiming of this exercise is to construct a model for quality regression analysis by deep learning methods. The tools I use are the most popular deep learning packages called Tensorflow (version 2.0) and API Keras. The importance of the feature is not the question I wanna discuss in this case. (Note, I've already analyzed dataset by some ensembling methods, which are the method that is easier to find the significant features. The result was the actually significant features are barely to find. Meaning, it seems the importance of each feature is approximately equal.)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.36</td>\n",
       "      <td>20.7</td>\n",
       "      <td>0.045</td>\n",
       "      <td>45.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.00100</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>8.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>6.3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.049</td>\n",
       "      <td>14.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.99400</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>8.1</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.40</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.050</td>\n",
       "      <td>30.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.99510</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.99560</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.99560</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4893</td>\n",
       "      <td>6.2</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.039</td>\n",
       "      <td>24.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0.99114</td>\n",
       "      <td>3.27</td>\n",
       "      <td>0.50</td>\n",
       "      <td>11.2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4894</td>\n",
       "      <td>6.6</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.36</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.047</td>\n",
       "      <td>57.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.15</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4895</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.19</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.041</td>\n",
       "      <td>30.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>0.99254</td>\n",
       "      <td>2.99</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4896</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.022</td>\n",
       "      <td>20.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.98869</td>\n",
       "      <td>3.34</td>\n",
       "      <td>0.38</td>\n",
       "      <td>12.8</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4897</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.020</td>\n",
       "      <td>22.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.98941</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.32</td>\n",
       "      <td>11.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4898 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0               7.0              0.27         0.36            20.7      0.045   \n",
       "1               6.3              0.30         0.34             1.6      0.049   \n",
       "2               8.1              0.28         0.40             6.9      0.050   \n",
       "3               7.2              0.23         0.32             8.5      0.058   \n",
       "4               7.2              0.23         0.32             8.5      0.058   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "4893            6.2              0.21         0.29             1.6      0.039   \n",
       "4894            6.6              0.32         0.36             8.0      0.047   \n",
       "4895            6.5              0.24         0.19             1.2      0.041   \n",
       "4896            5.5              0.29         0.30             1.1      0.022   \n",
       "4897            6.0              0.21         0.38             0.8      0.020   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                    45.0                 170.0  1.00100  3.00       0.45   \n",
       "1                    14.0                 132.0  0.99400  3.30       0.49   \n",
       "2                    30.0                  97.0  0.99510  3.26       0.44   \n",
       "3                    47.0                 186.0  0.99560  3.19       0.40   \n",
       "4                    47.0                 186.0  0.99560  3.19       0.40   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "4893                 24.0                  92.0  0.99114  3.27       0.50   \n",
       "4894                 57.0                 168.0  0.99490  3.15       0.46   \n",
       "4895                 30.0                 111.0  0.99254  2.99       0.46   \n",
       "4896                 20.0                 110.0  0.98869  3.34       0.38   \n",
       "4897                 22.0                  98.0  0.98941  3.26       0.32   \n",
       "\n",
       "      alcohol  quality  \n",
       "0         8.8        6  \n",
       "1         9.5        6  \n",
       "2        10.1        6  \n",
       "3         9.9        6  \n",
       "4         9.9        6  \n",
       "...       ...      ...  \n",
       "4893     11.2        6  \n",
       "4894      9.6        5  \n",
       "4895      9.4        6  \n",
       "4896     12.8        7  \n",
       "4897     11.8        6  \n",
       "\n",
       "[4898 rows x 12 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine = pd.read_csv('https://raw.githubusercontent.com/thisishugow/yhw/master/winequality-white.csv')\n",
    "dataset=wine ##preventing the raw data from being destroyed\n",
    "wine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize the features and separating it into training and testing sets\n",
    "Since the scale of the features are very different, I uses Z-scores to set the sdev to 1 and mean to 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in np.arange(0,11):\n",
    "    mean=np.mean(dataset.iloc[:,i])\n",
    "    std=np.std(dataset.iloc[:,i], ddof=1)\n",
    "    for m in np.arange(0, len(dataset)):\n",
    "        z_score = (dataset.iloc[m,i]-mean)/std\n",
    "        dataset.iloc[m,i] = z_score;\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(dataset.iloc[:,0:11], dataset.iloc[:,11].astype('float32'), \n",
    "                                                random_state=31, test_size=.3)                      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function 'train_test_split' helps separating the original datatest into the training set and testing set with ratio 7:3. '.astype('float')' transfer the type of the column from str to float since Tensorflow computes with float. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 16)                192       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 1,281\n",
      "Trainable params: 1,281\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential()  #load Sequential(), which is the major method for constructing a model\n",
    "model.add(keras.layers.Dense(16, activation = 'relu', input_shape=(11,)))\n",
    "\"\"\"\n",
    "input_shape is the dimension of the data which is necessary argument in the first layer.\n",
    "'activation'set as 'relu'ï¼ˆRectified Linear Unit, ReLUï¼‰which is widely applied in deep learning now, intead of Sigmoid.\n",
    "The number of dense unit(set to be 8 here) is subjectively based on my personal experience with no reason.\n",
    "\"\"\"\n",
    "model.add(keras.layers.Dense(32, kernel_regularizer=keras.regularizers.l2(0.001), activation = 'relu'))\n",
    "model.add(keras.layers.Dense(16,kernel_regularizer=keras.regularizers.l2(0.001), activation = 'relu'))\n",
    "model.add(keras.layers.Dense(1)) #Since this is a regression problem, the num of dense unit is one.\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### *keras.regularizers.l2(): Regularizer\n",
    "This is a method to avoid overfitting. The math detail here(https://en.wikipedia.org/wiki/Regularization_(mathematics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nAdam is the most popular optimizer and fits most problems.\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compiling the model.\n",
    "model.compile(keras.optimizers.Adam(0.001),  ## learning rate\n",
    "              loss= keras.losses.MeanSquaredError(),#\n",
    "              metrics=[keras.metrics.MeanSquaredError()])\n",
    "\"\"\"\n",
    "Adam is the most popular optimizer and fits most problems.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before the model is ready for training, it needs a few more settings. These are added during the model's *compile* step:\n",
    "\n",
    "\n",
    "* *Loss function* â€” An algorithm for measuring how far the model's outputs are from the desired output. The goal of training is this measures loss.\n",
    "* *Optimizer* â€”An algorithm for adjusting the inner parameters of the model in order to minimize loss.\n",
    "* *Metrics* â€”Used to monitor the training and testing steps. The following example uses *accuracy*, the fraction of the images that are correctly classified.\n",
    "\n",
    "Source: \"Basic classification: Classify images of clothing\", https://www.tensorflow.org/tutorials/keras/classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Starting to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3428 samples, validate on 1470 samples\n",
      "Epoch 1/100\n",
      "3428/3428 [==============================] - 1s 247us/sample - loss: 27.5922 - mean_squared_error: 27.5499 - val_loss: 10.6583 - val_mean_squared_error: 10.6145\n",
      "Epoch 2/100\n",
      "3428/3428 [==============================] - 0s 82us/sample - loss: 4.4132 - mean_squared_error: 4.3687 - val_loss: 2.6931 - val_mean_squared_error: 2.6489\n",
      "Epoch 3/100\n",
      "3428/3428 [==============================] - 0s 78us/sample - loss: 2.2252 - mean_squared_error: 2.1814 - val_loss: 1.9889 - val_mean_squared_error: 1.9455\n",
      "Epoch 4/100\n",
      "3428/3428 [==============================] - 0s 100us/sample - loss: 1.6259 - mean_squared_error: 1.5829 - val_loss: 1.5688 - val_mean_squared_error: 1.5261\n",
      "Epoch 5/100\n",
      "3428/3428 [==============================] - 0s 75us/sample - loss: 1.2753 - mean_squared_error: 1.2330 - val_loss: 1.2752 - val_mean_squared_error: 1.2333\n",
      "Epoch 6/100\n",
      "3428/3428 [==============================] - 0s 89us/sample - loss: 1.0526 - mean_squared_error: 1.0110 - val_loss: 1.0817 - val_mean_squared_error: 1.0405\n",
      "Epoch 7/100\n",
      "3428/3428 [==============================] - 0s 85us/sample - loss: 0.9114 - mean_squared_error: 0.8705 - val_loss: 0.9526 - val_mean_squared_error: 0.9120\n",
      "Epoch 8/100\n",
      "3428/3428 [==============================] - 0s 68us/sample - loss: 0.8108 - mean_squared_error: 0.7704 - val_loss: 0.8501 - val_mean_squared_error: 0.8100\n",
      "Epoch 9/100\n",
      "3428/3428 [==============================] - 0s 78us/sample - loss: 0.7408 - mean_squared_error: 0.7010 - val_loss: 0.7886 - val_mean_squared_error: 0.7489\n",
      "Epoch 10/100\n",
      "3428/3428 [==============================] - 0s 82us/sample - loss: 0.6923 - mean_squared_error: 0.6529 - val_loss: 0.7402 - val_mean_squared_error: 0.7010\n",
      "Epoch 11/100\n",
      "3428/3428 [==============================] - 0s 76us/sample - loss: 0.6606 - mean_squared_error: 0.6216 - val_loss: 0.6868 - val_mean_squared_error: 0.6480\n",
      "Epoch 12/100\n",
      "3428/3428 [==============================] - 0s 73us/sample - loss: 0.6357 - mean_squared_error: 0.5971 - val_loss: 0.6739 - val_mean_squared_error: 0.6355\n",
      "Epoch 13/100\n",
      "3428/3428 [==============================] - 0s 83us/sample - loss: 0.6134 - mean_squared_error: 0.5752 - val_loss: 0.6394 - val_mean_squared_error: 0.6014\n",
      "Epoch 14/100\n",
      "3428/3428 [==============================] - 0s 84us/sample - loss: 0.6028 - mean_squared_error: 0.5649 - val_loss: 0.6330 - val_mean_squared_error: 0.5953\n",
      "Epoch 15/100\n",
      "3428/3428 [==============================] - 0s 67us/sample - loss: 0.5955 - mean_squared_error: 0.5580 - val_loss: 0.6210 - val_mean_squared_error: 0.5837\n",
      "Epoch 16/100\n",
      "3428/3428 [==============================] - 0s 74us/sample - loss: 0.5812 - mean_squared_error: 0.5441 - val_loss: 0.6015 - val_mean_squared_error: 0.5646\n",
      "Epoch 17/100\n",
      "3428/3428 [==============================] - 0s 70us/sample - loss: 0.5719 - mean_squared_error: 0.5351 - val_loss: 0.5969 - val_mean_squared_error: 0.5603\n",
      "Epoch 18/100\n",
      "3428/3428 [==============================] - 0s 76us/sample - loss: 0.5662 - mean_squared_error: 0.5297 - val_loss: 0.5845 - val_mean_squared_error: 0.5481\n",
      "Epoch 19/100\n",
      "3428/3428 [==============================] - 0s 83us/sample - loss: 0.5631 - mean_squared_error: 0.5269 - val_loss: 0.6017 - val_mean_squared_error: 0.5657\n",
      "Epoch 20/100\n",
      "3428/3428 [==============================] - 0s 126us/sample - loss: 0.5521 - mean_squared_error: 0.5161 - val_loss: 0.5967 - val_mean_squared_error: 0.5608\n",
      "Epoch 21/100\n",
      "3428/3428 [==============================] - 0s 117us/sample - loss: 0.5516 - mean_squared_error: 0.5159 - val_loss: 0.5902 - val_mean_squared_error: 0.5545\n",
      "Epoch 22/100\n",
      "3428/3428 [==============================] - 0s 133us/sample - loss: 0.5544 - mean_squared_error: 0.5190 - val_loss: 0.5804 - val_mean_squared_error: 0.5451\n",
      "Epoch 23/100\n",
      "3428/3428 [==============================] - 0s 107us/sample - loss: 0.5443 - mean_squared_error: 0.5091 - val_loss: 0.5660 - val_mean_squared_error: 0.5308\n",
      "Epoch 24/100\n",
      "3428/3428 [==============================] - 0s 93us/sample - loss: 0.5475 - mean_squared_error: 0.5124 - val_loss: 0.5596 - val_mean_squared_error: 0.5246\n",
      "Epoch 25/100\n",
      "3428/3428 [==============================] - 0s 79us/sample - loss: 0.5376 - mean_squared_error: 0.5027 - val_loss: 0.5625 - val_mean_squared_error: 0.5276\n",
      "Epoch 26/100\n",
      "3428/3428 [==============================] - 0s 116us/sample - loss: 0.5412 - mean_squared_error: 0.5064 - val_loss: 0.5573 - val_mean_squared_error: 0.5226\n",
      "Epoch 27/100\n",
      "3428/3428 [==============================] - 0s 112us/sample - loss: 0.5315 - mean_squared_error: 0.4969 - val_loss: 0.5519 - val_mean_squared_error: 0.5174\n",
      "Epoch 28/100\n",
      "3428/3428 [==============================] - 0s 117us/sample - loss: 0.5274 - mean_squared_error: 0.4929 - val_loss: 0.5527 - val_mean_squared_error: 0.5182\n",
      "Epoch 29/100\n",
      "3428/3428 [==============================] - 0s 139us/sample - loss: 0.5254 - mean_squared_error: 0.4910 - val_loss: 0.5488 - val_mean_squared_error: 0.5144\n",
      "Epoch 30/100\n",
      "3428/3428 [==============================] - 0s 123us/sample - loss: 0.5205 - mean_squared_error: 0.4861 - val_loss: 0.5539 - val_mean_squared_error: 0.5196\n",
      "Epoch 31/100\n",
      "3428/3428 [==============================] - 0s 99us/sample - loss: 0.5203 - mean_squared_error: 0.4860 - val_loss: 0.5431 - val_mean_squared_error: 0.5089\n",
      "Epoch 32/100\n",
      "3428/3428 [==============================] - 0s 78us/sample - loss: 0.5149 - mean_squared_error: 0.4807 - val_loss: 0.5453 - val_mean_squared_error: 0.5112\n",
      "Epoch 33/100\n",
      "3428/3428 [==============================] - 0s 80us/sample - loss: 0.5164 - mean_squared_error: 0.4822 - val_loss: 0.5464 - val_mean_squared_error: 0.5122\n",
      "Epoch 34/100\n",
      "3428/3428 [==============================] - 0s 87us/sample - loss: 0.5109 - mean_squared_error: 0.4767 - val_loss: 0.5444 - val_mean_squared_error: 0.5103\n",
      "Epoch 35/100\n",
      "3428/3428 [==============================] - 0s 111us/sample - loss: 0.5082 - mean_squared_error: 0.4741 - val_loss: 0.5789 - val_mean_squared_error: 0.5448\n",
      "Epoch 36/100\n",
      "3428/3428 [==============================] - 0s 121us/sample - loss: 0.5152 - mean_squared_error: 0.4811 - val_loss: 0.5691 - val_mean_squared_error: 0.5350\n",
      "Epoch 37/100\n",
      "3428/3428 [==============================] - 0s 108us/sample - loss: 0.5076 - mean_squared_error: 0.4735 - val_loss: 0.5491 - val_mean_squared_error: 0.5151\n",
      "Epoch 38/100\n",
      "3428/3428 [==============================] - 0s 104us/sample - loss: 0.4991 - mean_squared_error: 0.4652 - val_loss: 0.5407 - val_mean_squared_error: 0.5067\n",
      "Epoch 39/100\n",
      "3428/3428 [==============================] - 0s 70us/sample - loss: 0.4999 - mean_squared_error: 0.4660 - val_loss: 0.5497 - val_mean_squared_error: 0.5159\n",
      "Epoch 40/100\n",
      "3428/3428 [==============================] - 0s 77us/sample - loss: 0.4951 - mean_squared_error: 0.4612 - val_loss: 0.5348 - val_mean_squared_error: 0.5010\n",
      "Epoch 41/100\n",
      "3428/3428 [==============================] - 0s 75us/sample - loss: 0.4922 - mean_squared_error: 0.4583 - val_loss: 0.5573 - val_mean_squared_error: 0.5235\n",
      "Epoch 42/100\n",
      "3428/3428 [==============================] - 0s 75us/sample - loss: 0.4949 - mean_squared_error: 0.4611 - val_loss: 0.5442 - val_mean_squared_error: 0.5104\n",
      "Epoch 43/100\n",
      "3428/3428 [==============================] - 0s 71us/sample - loss: 0.4892 - mean_squared_error: 0.4555 - val_loss: 0.5438 - val_mean_squared_error: 0.5102\n",
      "Epoch 44/100\n",
      "3428/3428 [==============================] - 0s 71us/sample - loss: 0.4849 - mean_squared_error: 0.4512 - val_loss: 0.5509 - val_mean_squared_error: 0.5173\n",
      "Epoch 45/100\n",
      "3428/3428 [==============================] - 0s 80us/sample - loss: 0.4878 - mean_squared_error: 0.4542 - val_loss: 0.5336 - val_mean_squared_error: 0.5000\n",
      "Epoch 46/100\n",
      "3428/3428 [==============================] - 0s 76us/sample - loss: 0.4869 - mean_squared_error: 0.4533 - val_loss: 0.5343 - val_mean_squared_error: 0.5008\n",
      "Epoch 47/100\n",
      "3428/3428 [==============================] - 0s 122us/sample - loss: 0.4831 - mean_squared_error: 0.4496 - val_loss: 0.5476 - val_mean_squared_error: 0.5141\n",
      "Epoch 48/100\n",
      "3428/3428 [==============================] - 0s 121us/sample - loss: 0.4827 - mean_squared_error: 0.4492 - val_loss: 0.5357 - val_mean_squared_error: 0.5022\n",
      "Epoch 49/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3428/3428 [==============================] - 0s 89us/sample - loss: 0.4811 - mean_squared_error: 0.4476 - val_loss: 0.5341 - val_mean_squared_error: 0.5006\n",
      "Epoch 50/100\n",
      "3428/3428 [==============================] - 0s 73us/sample - loss: 0.4789 - mean_squared_error: 0.4454 - val_loss: 0.5329 - val_mean_squared_error: 0.4995\n",
      "Epoch 51/100\n",
      "3428/3428 [==============================] - 0s 99us/sample - loss: 0.4791 - mean_squared_error: 0.4457 - val_loss: 0.5518 - val_mean_squared_error: 0.5185\n",
      "Epoch 52/100\n",
      "3428/3428 [==============================] - 0s 77us/sample - loss: 0.4764 - mean_squared_error: 0.4431 - val_loss: 0.5340 - val_mean_squared_error: 0.5006\n",
      "Epoch 53/100\n",
      "3428/3428 [==============================] - 0s 82us/sample - loss: 0.4758 - mean_squared_error: 0.4425 - val_loss: 0.5367 - val_mean_squared_error: 0.5034\n",
      "Epoch 54/100\n",
      "3428/3428 [==============================] - 0s 133us/sample - loss: 0.4721 - mean_squared_error: 0.4388 - val_loss: 0.5403 - val_mean_squared_error: 0.5071\n",
      "Epoch 55/100\n",
      "3428/3428 [==============================] - 0s 124us/sample - loss: 0.4720 - mean_squared_error: 0.4387 - val_loss: 0.5305 - val_mean_squared_error: 0.4973\n",
      "Epoch 56/100\n",
      "3428/3428 [==============================] - 0s 116us/sample - loss: 0.4765 - mean_squared_error: 0.4433 - val_loss: 0.5548 - val_mean_squared_error: 0.5217\n",
      "Epoch 57/100\n",
      "3428/3428 [==============================] - 0s 98us/sample - loss: 0.4742 - mean_squared_error: 0.4411 - val_loss: 0.5315 - val_mean_squared_error: 0.4984\n",
      "Epoch 58/100\n",
      "3428/3428 [==============================] - 0s 114us/sample - loss: 0.4710 - mean_squared_error: 0.4380 - val_loss: 0.5481 - val_mean_squared_error: 0.5150\n",
      "Epoch 59/100\n",
      "3428/3428 [==============================] - 0s 110us/sample - loss: 0.4699 - mean_squared_error: 0.4369 - val_loss: 0.5375 - val_mean_squared_error: 0.5045\n",
      "Epoch 60/100\n",
      "3428/3428 [==============================] - 0s 110us/sample - loss: 0.4694 - mean_squared_error: 0.4364 - val_loss: 0.5408 - val_mean_squared_error: 0.5079\n",
      "Epoch 61/100\n",
      "3428/3428 [==============================] - 0s 117us/sample - loss: 0.4651 - mean_squared_error: 0.4322 - val_loss: 0.5363 - val_mean_squared_error: 0.5034\n",
      "Epoch 62/100\n",
      "3428/3428 [==============================] - 0s 107us/sample - loss: 0.4681 - mean_squared_error: 0.4351 - val_loss: 0.5348 - val_mean_squared_error: 0.5019\n",
      "Epoch 63/100\n",
      "3428/3428 [==============================] - 0s 84us/sample - loss: 0.4644 - mean_squared_error: 0.4316 - val_loss: 0.5286 - val_mean_squared_error: 0.4958\n",
      "Epoch 64/100\n",
      "3428/3428 [==============================] - 0s 74us/sample - loss: 0.4635 - mean_squared_error: 0.4306 - val_loss: 0.5309 - val_mean_squared_error: 0.4982\n",
      "Epoch 65/100\n",
      "3428/3428 [==============================] - 0s 71us/sample - loss: 0.4599 - mean_squared_error: 0.4270 - val_loss: 0.5578 - val_mean_squared_error: 0.5249\n",
      "Epoch 66/100\n",
      "3428/3428 [==============================] - 0s 72us/sample - loss: 0.4637 - mean_squared_error: 0.4309 - val_loss: 0.5339 - val_mean_squared_error: 0.5011\n",
      "Epoch 67/100\n",
      "3428/3428 [==============================] - 0s 74us/sample - loss: 0.4640 - mean_squared_error: 0.4312 - val_loss: 0.5460 - val_mean_squared_error: 0.5133\n",
      "Epoch 68/100\n",
      "3428/3428 [==============================] - 0s 75us/sample - loss: 0.4625 - mean_squared_error: 0.4298 - val_loss: 0.5363 - val_mean_squared_error: 0.5035\n",
      "Epoch 69/100\n",
      "3428/3428 [==============================] - 0s 111us/sample - loss: 0.4620 - mean_squared_error: 0.4293 - val_loss: 0.5297 - val_mean_squared_error: 0.4971\n",
      "Epoch 70/100\n",
      "3428/3428 [==============================] - 0s 114us/sample - loss: 0.4556 - mean_squared_error: 0.4229 - val_loss: 0.5425 - val_mean_squared_error: 0.5099\n",
      "Epoch 71/100\n",
      "3428/3428 [==============================] - 0s 95us/sample - loss: 0.4611 - mean_squared_error: 0.4284 - val_loss: 0.5413 - val_mean_squared_error: 0.5087\n",
      "Epoch 72/100\n",
      "3428/3428 [==============================] - 0s 79us/sample - loss: 0.4590 - mean_squared_error: 0.4264 - val_loss: 0.5551 - val_mean_squared_error: 0.5225\n",
      "Epoch 73/100\n",
      "3428/3428 [==============================] - 0s 79us/sample - loss: 0.4586 - mean_squared_error: 0.4260 - val_loss: 0.5347 - val_mean_squared_error: 0.5021\n",
      "Epoch 74/100\n",
      "3428/3428 [==============================] - 0s 74us/sample - loss: 0.4576 - mean_squared_error: 0.4250 - val_loss: 0.5424 - val_mean_squared_error: 0.5098\n",
      "Epoch 75/100\n",
      "3428/3428 [==============================] - 0s 80us/sample - loss: 0.4557 - mean_squared_error: 0.4231 - val_loss: 0.5397 - val_mean_squared_error: 0.5072\n",
      "Epoch 76/100\n",
      "3428/3428 [==============================] - 0s 78us/sample - loss: 0.4549 - mean_squared_error: 0.4224 - val_loss: 0.5540 - val_mean_squared_error: 0.5214\n",
      "Epoch 77/100\n",
      "3428/3428 [==============================] - 0s 71us/sample - loss: 0.4553 - mean_squared_error: 0.4228 - val_loss: 0.5329 - val_mean_squared_error: 0.5004\n",
      "Epoch 78/100\n",
      "3428/3428 [==============================] - 0s 74us/sample - loss: 0.4572 - mean_squared_error: 0.4248 - val_loss: 0.5406 - val_mean_squared_error: 0.5082\n",
      "Epoch 79/100\n",
      "3428/3428 [==============================] - 0s 83us/sample - loss: 0.4544 - mean_squared_error: 0.4220 - val_loss: 0.5399 - val_mean_squared_error: 0.5075\n",
      "Epoch 80/100\n",
      "3428/3428 [==============================] - 0s 120us/sample - loss: 0.4534 - mean_squared_error: 0.4210 - val_loss: 0.5401 - val_mean_squared_error: 0.5078\n",
      "Epoch 81/100\n",
      "3428/3428 [==============================] - 0s 113us/sample - loss: 0.4523 - mean_squared_error: 0.4199 - val_loss: 0.5479 - val_mean_squared_error: 0.5155\n",
      "Epoch 82/100\n",
      "3428/3428 [==============================] - 0s 106us/sample - loss: 0.4518 - mean_squared_error: 0.4194 - val_loss: 0.5530 - val_mean_squared_error: 0.5206\n",
      "Epoch 83/100\n",
      "3428/3428 [==============================] - 0s 115us/sample - loss: 0.4536 - mean_squared_error: 0.4212 - val_loss: 0.5315 - val_mean_squared_error: 0.4992\n",
      "Epoch 84/100\n",
      "3428/3428 [==============================] - 0s 120us/sample - loss: 0.4486 - mean_squared_error: 0.4163 - val_loss: 0.5466 - val_mean_squared_error: 0.5143\n",
      "Epoch 85/100\n",
      "3428/3428 [==============================] - 0s 137us/sample - loss: 0.4487 - mean_squared_error: 0.4164 - val_loss: 0.5389 - val_mean_squared_error: 0.5066\n",
      "Epoch 86/100\n",
      "3428/3428 [==============================] - 0s 107us/sample - loss: 0.4512 - mean_squared_error: 0.4189 - val_loss: 0.5724 - val_mean_squared_error: 0.5402\n",
      "Epoch 87/100\n",
      "3428/3428 [==============================] - 0s 106us/sample - loss: 0.4533 - mean_squared_error: 0.4211 - val_loss: 0.5392 - val_mean_squared_error: 0.5070\n",
      "Epoch 88/100\n",
      "3428/3428 [==============================] - 0s 110us/sample - loss: 0.4513 - mean_squared_error: 0.4190 - val_loss: 0.5615 - val_mean_squared_error: 0.5293\n",
      "Epoch 89/100\n",
      "3428/3428 [==============================] - 0s 116us/sample - loss: 0.4557 - mean_squared_error: 0.4235 - val_loss: 0.5368 - val_mean_squared_error: 0.5045\n",
      "Epoch 90/100\n",
      "3428/3428 [==============================] - 0s 81us/sample - loss: 0.4500 - mean_squared_error: 0.4178 - val_loss: 0.5415 - val_mean_squared_error: 0.5093\n",
      "Epoch 91/100\n",
      "3428/3428 [==============================] - 0s 71us/sample - loss: 0.4439 - mean_squared_error: 0.4117 - val_loss: 0.5456 - val_mean_squared_error: 0.5134\n",
      "Epoch 92/100\n",
      "3428/3428 [==============================] - 0s 72us/sample - loss: 0.4431 - mean_squared_error: 0.4109 - val_loss: 0.5506 - val_mean_squared_error: 0.5184\n",
      "Epoch 93/100\n",
      "3428/3428 [==============================] - 0s 74us/sample - loss: 0.4474 - mean_squared_error: 0.4152 - val_loss: 0.5512 - val_mean_squared_error: 0.5190\n",
      "Epoch 94/100\n",
      "3428/3428 [==============================] - 0s 74us/sample - loss: 0.4445 - mean_squared_error: 0.4123 - val_loss: 0.5406 - val_mean_squared_error: 0.5084\n",
      "Epoch 95/100\n",
      "3428/3428 [==============================] - 0s 77us/sample - loss: 0.4403 - mean_squared_error: 0.4081 - val_loss: 0.5663 - val_mean_squared_error: 0.5341\n",
      "Epoch 96/100\n",
      "3428/3428 [==============================] - 0s 79us/sample - loss: 0.4372 - mean_squared_error: 0.4050 - val_loss: 0.5446 - val_mean_squared_error: 0.5124\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3428/3428 [==============================] - 0s 75us/sample - loss: 0.4415 - mean_squared_error: 0.4093 - val_loss: 0.5444 - val_mean_squared_error: 0.5122\n",
      "Epoch 98/100\n",
      "3428/3428 [==============================] - 0s 79us/sample - loss: 0.4356 - mean_squared_error: 0.4034 - val_loss: 0.5384 - val_mean_squared_error: 0.5063\n",
      "Epoch 99/100\n",
      "3428/3428 [==============================] - 0s 80us/sample - loss: 0.4391 - mean_squared_error: 0.4069 - val_loss: 0.5374 - val_mean_squared_error: 0.5052\n",
      "Epoch 100/100\n",
      "3428/3428 [==============================] - 0s 115us/sample - loss: 0.4419 - mean_squared_error: 0.4097 - val_loss: 0.5384 - val_mean_squared_error: 0.5063\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "history = model.fit(xtrain, ytrain,\n",
    "                    batch_size=32,\n",
    "                    epochs=100,\n",
    "                    validation_data=(xtest,ytest),\n",
    "                    steps_per_epoch=math.ceil(len(xtrain)/32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ploting the loss and mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f08dc2b51d0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pylab as plt\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f09080d8e10>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEGCAYAAABiq/5QAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAeq0lEQVR4nO3de7AcZ53e8e+vu2fm3K2rjSy5kADHGDtYYOGINbic9ZLyJYtN2OWyQAw40W4Kdu0FKnHYVAG7qYo3iyE44bLGNhgCziYYx4YIL6DYUARskEAxkkUQNjY6WFgH2ZKOdG4z3b/80e/MmSMd6eg2Z6Tu51N1amZ6Zrrf7p7zzDtvv/22uTsiIlIeUbcLICIi80vBLyJSMgp+EZGSUfCLiJSMgl9EpGSSbhfgaCxZssRXrlzZ7WKIiJxWNm3a9Ft3X3rw9NMi+FeuXMnGjRu7XQwRkdOKmT0923Q19YiIlIyCX0SkZBT8IiIlc1q08YuIHKt6vc7w8DATExPdLkrH9fT0sGLFCiqVylG9XsEvIoU0PDzM4OAgK1euxMy6XZyOcXd2797N8PAwq1atOqr3qKlHRAppYmKCxYsXFzr0AcyMxYsXH9MvGwW/iBRW0UO/6VjXs9DBv2Hbs3zq4V90uxgiIqeUQgf/d34+wu3ffbLbxRCRktqzZw+f+tSnjvl9V199NXv27OlAiXKFDv44MtJUF5oRke44XPCnaXrE961fv54FCxZ0qljF7tVTiSPqWdbtYohISd1888088cQTrF69mkqlwsDAAMuWLWPz5s08/vjjXHfddezYsYOJiQluvPFG1q1bB0wPU7N//36uuuoqXvOa1/D973+f5cuXc//999Pb23tC5Sp08CeR0VCNX6T0PvK1rTz+zL6TOs+XnT3Eh37/giO+5pZbbmHLli1s3ryZhx9+mGuuuYYtW7a0ul3eddddLFq0iPHxcV71qlfxxje+kcWLF8+Yx/bt27nnnnv47Gc/y5ve9Cbuvfde3v72t59Q2Ysf/Jnj7qU5ui8ip65LLrlkRl/72267jfvuuw+AHTt2sH379kOCf9WqVaxevRqAiy++mKeeeuqEy1Hs4I/zQxhp5iSxgl+krOaqmc+X/v7+1v2HH36Yb3/72/zgBz+gr6+Pyy+/fNa++LVarXU/jmPGx8dPuByFPrjbDPtGpuYeEZl/g4ODjI6Ozvrc3r17WbhwIX19ffzsZz/jkUcembdyFbvGHyn4RaR7Fi9ezKWXXsqFF15Ib28vZ511Vuu5K6+8ks985jO8/OUv57zzzmPt2rXzVq6CB3/+g6aRqmePiHTHl7/85Vmn12o1vvGNb8z6XLMdf8mSJWzZsqU1/QMf+MBJKVOhm3oqoamnrp49IiIthQ7+OJo+uCsiIrlCB3/SqvGrqUdEpKnQwV9Rrx4RkUMUOvinm3pU4xcRaSp08FciHdwVETlYoYO/eeauxusRkW4o3bDMZnaOmT1kZtvMbKuZ3Rimf9jMfm1mm8Pf1Z0qw/QJXGrqEZH5V8ZhmRvA+939x2Y2CGwys2+F5z7u7h/t4LIBDdkgIt1VumGZ3X0nsDPcHzWzbcDyTi1vNtNn7ir4RUrtGzfDb356cuf5gn8IV91yxJecqsMyz0sbv5mtBF4BPBomvdfMHjOzu8xs4WHes87MNprZxpGRkeNa7nSNX009ItJ9sw3LfNFFF7F27drWsMwHOy2HZTazAeBe4CZ332dmnwb+CvBweyvw7oPf5+63A7cDrFmz5riq7K02ftX4Rcptjpr5fCnFsMxmViEP/S+5+1cB3P1Zd0/dPQM+C1zSqeVXmr161MYvIl1QumGZLb/k1Z3ANnf/WNv0ZaH9H+ANwJbZ3n8yxK0av5p6RGT+lXFY5kuBdwA/NbPNYdoHgbea2Wrypp6ngD/uVAFao3Oqxi8iXXIqDsvcyV493wNmu97h+k4t82CJhmwQETlEoc/cjTVkg4jIIQod/BUN2SBSau7l+N8/1vUsdPA3+/GrqUekfHp6eti9e3fhw9/d2b17Nz09PUf9noJfc1dNPSJltWLFCoaHhzneE0BPJz09PaxYseKoX1/s4G/141eNX6RsKpXKjLNkZVqxm3oiDdImInKwcgS/mnpERFoKHfw6c1dE5FCFDn4zoxKbmnpERNoUOvghr/Ur+EVEphU++CtRRF1NPSIiLYUP/iQ2UtX4RURaCh/8cRTpBC4RkTaFD/5KbOrVIyLSpvDBr6YeEZGZih/8UaQLsYiItClB8KupR0SkXeGDX/34RURmKnzwV+JINX4RkTaFD/5EQzaIiMxQ/OCPTKNzioi0KUHwR7oQi4hIm+IHf2w6c1dEpE3xgz/SCVwiIu2KH/yxRucUEWlX+ODXhVhERGYqfPDHUaSmHhGRNh0LfjM7x8weMrNtZrbVzG4M0xeZ2bfMbHu4XdipMgBUIlNTj4hIm07W+BvA+939fGAt8B4zexlwM7DB3c8FNoTHHZPE6scvItKuY8Hv7jvd/cfh/iiwDVgOXAvcHV52N3Bdp8oAeVOP2vhFRKbNSxu/ma0EXgE8Cpzl7jsh/3IAzjzMe9aZ2UYz2zgyMnLcy84P7qqpR0SkqePBb2YDwL3ATe6+72jf5+63u/sad1+zdOnS415+EkVq6hERadPR4DezCnnof8ndvxomP2tmy8Lzy4BdnSxDohq/iMgMnezVY8CdwDZ3/1jbUw8A14f71wP3d6oMoEHaREQOlnRw3pcC7wB+amabw7QPArcA/93MbgB+BfxhB8tAEucHd92d/LtIRKTcOhb87v494HBJe0WnlnuwJMqLkGZOEiv4RUQKf+ZuM+zVpVNEJFf44K9E+Srq7F0RkVzhgz9ua+oREZESBH8lNPXoYiwiIrnCB38S56uovvwiIrnCB3+zqUd9+UVEcoUP/op69YiIzFD44E9Cr56GevWIiAClCH7V+EVE2hU/+JsHd9XGLyIClCL4Q3dO9eoREQHKEPw6gUtEZIYSBL+GbBARaVf44G9151Qbv4gIUILg11g9IiIzFT74K7GaekRE2hU++Ju9elTjFxHJFT/4o2Z3TgW/iAiUIvg1ZIOISLviB78GaRMRmaH4wR9pyAYRkXbFD/5WjV9NPSIiUILgr6jGLyIyQ+GDP1aNX0RkhsIHf6s7p2r8IiJACYK/eeauTuASEckVPvhDhV/9+EVEgo4Fv5ndZWa7zGxL27QPm9mvzWxz+Lu6U8tvWyaV2HTmrohI0Mka/+eBK2eZ/nF3Xx3+1ndw+S1xZGrqEREJOhb87v5d4LlOzf9YVKJIo3OKiARHDH4ze3vb/UsPeu69x7nM95rZY6EpaOFxzuOYJLGpH7+ISDBXjf99bff/80HPvfs4lvdp4MXAamAncOvhXmhm68xso5ltHBkZOY5FTYujSGP1iIgEcwW/Heb+bI/n5O7Punvq7hnwWeCSI7z2dndf4+5rli5deqyLmqESm3r1iIgEcwW/H+b+bI/nZGbL2h6+AdhyuNeeTElsqvGLiATJHM+/1MweI6/dvzjcJzx+0ZHeaGb3AJcDS8xsGPgQcLmZrSb/0ngK+OPjL/rRS9TUIyLSMlfwn3+8M3b3t84y+c7jnd+JSCI19YiINB0x+N396fbHZrYYuAz4lbtv6mTBTqYkjjRWj4hIMFd3zq+b2YXh/jLyNvl3A180s5vmoXwnRRIZqUbnFBEB5j64u8rdmwdg3wV8y91/H/hHHF93zq7QwV0RkWlzBX+97f4VwHoAdx8FTpsqtM7cFRGZNtfB3R1m9qfAMPBK4EEAM+sFKh0u20kTR6YLsYiIBHPV+G8ALgDeCbzZ3feE6WuBz3WwXCdVEpsO7oqIBHP16tkF/Mks0x8CHupUoU62Shypxi8iEhwx+M3sgSM97+6vP7nF6Yw40iBtIiJNc7XxvxrYAdwDPMpxjM9zKqioV4+ISMtcwf8C4HXAW4E/Av4XcI+7b+10wU6mJIp05q6ISHDEg7thJM0H3f168gO6vwAeDj19ThtJpBq/iEjTXDV+zKwGXENe618J3AZ8tbPFOrl0IRYRkWlzHdy9G7gQ+AbwkbazeE8riXr1iIi0zFXjfwdwAPgHwJ+ZtY7tGuDuPtTBsp00auoREZk2Vz/+jl2MfT7lB3cV/CIiMPeZu4VQiU1j9YiIBKUI/jgyUjX1iIgAJQn+/OCu467wFxEpRfBXovygtA7wioiUJPjjOA9+NfeIiJQk+CtRvpo6wCsiUpLgT0KNX106RUTKEvxq4xcRaSlH8Mf5amrYBhGRsgR/pKYeEZGmOUfnPK3tewbGdpPECwE19YiIQNFr/N/9G/jCtSShV48uxiIiUvTgrw3C5H4qoVdPXU09IiKdC34zu8vMdpnZlrZpi8zsW2a2Pdwu7NTyAagOQjpJ4g1AJ3CJiEBna/yfB648aNrNwAZ3PxfYEB53Tm0wv/ExAOrq1SMi0rngd/fvAs8dNPla4O5w/27guk4tH4DaAAA9aR786tUjIjL/bfxnuftOgHB75uFeaGbrzGyjmW0cGRk5vqWFGn81PQCoH7+ICJzCB3fd/XZ3X+Pua5YuXXp8M6nmNf5aM/hV4xcRmffgf9bMlgGE210dXVotvyRwpdnUoxq/iMi8B/8DwPXh/vXA/R1dWmjqqTT2A6rxi4hAZ7tz3gP8ADjPzIbN7AbgFuB1ZrYdeF143Dnh4G6l0WzjV/CLiHRsyAZ3f+thnrqiU8s8RKvGnwe/xuMXETmFD+6eFOHgblLPm3p0ApeISNGDP4qh0k/cUK8eEZGmYgc/QG2AONT4deauiEgpgn+QuJ7X+NXUIyJSkuCPmjV+NfWIiJQg+KsDRFPNg7tq6hERKX7w14awqVFANX4REShF8A+0gl+9ekREShH8+VW4QE09IiJQhuCvDmCTo1Rio65ePSIiJQj+2iBkdXqjVBdbFxGhFMGfD828IJrQIG0iIpQi+PPxeoaiCR3cFRGhFMGfj9B5RjyhC7GIiFCG4A8jdA7ZuGr8IiKUIfhDG/+g2vhFRIBSBH+o8TOhC7GIiFCK4M/b+PttXKNziohQhuAPbfyDNqGxekREKFHw9zOuXj0iIpQh+KMIqoP0o6YeEREoQ/AD1AboZ1wHd0VEKE3wD9LPmPrxi4hQluCvDtDn4+rHLyJCWYK/Nkiv6+CuiAiUKPj7MjX1iIhAiYK/x8fU1CMiAiTdWKiZPQWMAinQcPc1HV1gbZCebEwXYhERoUvBH/xjd//tvCypOkBPNka9oeAXESlNU09MSpJNdrskIiJd163gd+CbZrbJzNbN9gIzW2dmG81s48jIyIktLQzUVs3GTmw+IiIF0K3gv9TdXwlcBbzHzC47+AXufru7r3H3NUuXLj2xpYXgr6UHTmw+IiIF0JXgd/dnwu0u4D7gko4uMAzU1uuq8YuIzHvwm1m/mQ027wP/BNjS0YW2avwKfhGRbvTqOQu4z8yay/+yuz/Y0SWG4FeNX0SkC8Hv7k8CF83rQlvBP86ufROcOdQzr4sXETmVlKY7J8CgjbP1mX1dLoyISHeVI/jbrsK19Zm9XS6MiEh3lST4+wFjRV9DNX4RKb1uDtkwf8ygNsiK3owtqvGLSMmVo8YPUBtkWU+dHc+Ns3es3u3SiIh0TXmCvzrAkko+Vs/Wnar1i0h5lSf4a4OcEefB/7ja+UWkxEoV/NXGAV4w1MOWX6vGLyLlVaLgH4DJ/Vxw9pB69ohIqZUo+IdgcpQLlp/BEyP7GZ9Ku10iEZGuKE/wVwdgapQLzh4ic9j2G9X6RaScyhP8fYtgYh8XDeaBr+YeESmr8gT/6rdB0sNZP/hLFvRV2KoDvCJSUuUJ/gXnwGUfwLZ9jbcs+rlq/CJSWuUJfoDf+VNY9GLWjX6GJ3/zHPsnG90ukYjIvCtX8Cc1uPo/smhyB++0r/FXX3u82yUSEZl35Qp+gJf8Hpz/em6q3s8vN32TB7f8ptslEhGZV+ULfoBrbiVZtJK7a3/DV+69h2f3TXS7RCIi86acwT9wJvbOrxMvPIfbsv/AHV/8Ao0063apRETmRTmDH2DgTKo3rGdqcAXv2/UXfPG/fJh941PdLpWISMeVN/gBBs5kwZ/8PXuWXMy7nv8Ej3/0Sn719JPdLpWISEeVO/gBBpay7D3r+eWrPsTq9DGGPvdaNn3hg0yO/rbbJRMR6QgFP0AUseqa9/Hc2zbwVO2lXPzkJ8lufRnbP/+vmHzqUcjU/i8ixWHu3u0yzGnNmjW+cePGeVmWu/OTH32fPRtu5bUTD1OxlH3xQvaecwWLX/46+l5yGQydPS9lERE5EWa2yd3XHDJdwT87d+fRrU/w1KP3s3DHt3m1/4QhGwfguerZjC08j8rScxlacR69S1bBGStgaHk+7r+IyClAwX8CGmnGj54c4ZdbHyH95f/hzD2bWeXDvNB2UbOZF24/EA+xr7aM8f7lZD0Liau9JNUeop4h4oGlVAaXUOlfQBLHJJUqlUoVS2r5WcVJLR8+utIHlV6wCMwOX7AsBQwitdiJyKEU/CdRmjnDz4+xfededg4/wcRvnybbM0xl/68ZmnqWJY1nWcEuhmyMGlPUqNNz0BfEUS+LiIyIulWoUyG1hKpP0eMTJDRmvs5iMmJSi0ktISWhYRUaUZWGVWlENTJL8ueJMSAyJzYHjIwID/MhisMXT4SFL5/8JsItyr9vyIg8w3CyqEoWJWRWwQwiHCN8tsJnzAzMDAOqjX3Upp6nNrUHd0ijSl62uJc06SOt9OFxDeIKFlUwwLyOZXWwiCzugaQHw4kbB0jq+7GsThbXSKMaHiVEFuXLxIk8xbyBuZMlPWRxL1lSg3zO4BlRNkWUThJlUxBV8LhKFlex1hewQSg/ZkTpJFYfI2qM4URQ6cMrvRAlgEPYNuaOkeXvj6sQJbg7NrkPpkahMYlXB/DaECS1fL6NcawxCXElvKeSF9XDfC3CogiL4rYtbfl+ixKiKA7rFp6tHyCa3IdN5KPSZtXBfHlRDI1JSCfzV0dheXGSr0eU5J+TdBJLpyDNuzw7hnsG6RRWH4esjlX68l+8lX7wFNI6ZI0Z2460DvXxfJlJNa/o1Abz57N6/nzzc8NBlR5P88pOc77Nx2ZQHcyXHVfzeTfG89dFSb6OAOPPw4HdMLkPes7Ih2rvWZC/fnIU6gcg6ckv2tQzlH/+szRfjmf5sT7PppfbnN5kEcS1vAyewsQ+mNibr1e1f7pS16rMNfdXDBZPb6ewhVv/O5f8Szjz/KNMjJkOF/zJcc2t5OLIeOHifl64uB8uPBt47Yzn3Z2xqZR9E3WenWgwOlFn/4ExpkZ/S7p/hGxilLSRkqZ1PJ3C0nrrH8ga48T1A1hjAm9+wLIGUVYn8SkibzBJjUmrMUmVzB1P83+CiIzYM2IaJKRUSKlQJ8mmqPgU1WySPPKnqJDiQOpG+N1ATJbPgywPSjLMnfaqQUQIM5yMiEaI+ISUXqtToRG+QJqRM/OftxlRe72f3T7IHl5AhlGhQZUGvUzQZ3voZ5IqdSrWCGU1pkhoeExERo/V6WEKB0bp43nvoU5ClTq18L72a6w1PKZBHpI9NkUvk/Qz88t4kgoTVKl7TGwZNepUqbe+xKxtHQxnkgoH6GHMaxhOn03SR76Nm9sgw1pf3hEZCSnV8IU9Sh/7vI86Cf1MMGDj9DLJODUmqDLlSascSdhfzfk291dMFrZ0Xq7mPozC2jdLPk6Nvd7PKH0ADDLGoI0RkTFFhUkqeNgP+V8a5p9iOGNUmaRCg3j6c44x6fl7U2J6mKTfJuhlMq+shE9b/rnJS1InydeNhCop/YzTzwTgNMj3UUbU2t7tnz1vm2dK1LqNyehlgn7GqdII61OlbklrmxvOXgZ43ocYpY8BnmchT3MGB5igwgH6GKdGjSkGGGOQMYzpildmUdj2FrZus6JlrUJGZGHb1XGM/dbPfvpJLaGX5+n3vCJIWK/Incjy8jX/r1p539qr8MyCy7ngOIP/cLoS/GZ2JfAJIAbucPdbulGOTjEz+msJ/bWEZWc0py4CVnSxVCcmyzz/kiGvhGSeP04zJ2v773TPHzeyjCwLtfzmPBxSd9LU6cPpcTjbnTiy1p87NFKnnmVMZs7+NKORzvzy8day819fjucVYc9bvUKdnMydRuakWZb/qghljQwiM8xaP0bCeuXPZ22/gt2Znn94TXPezChT/pceMn16nu3bycgrEHGzHG2vbW5fb/vS9Vm2cXP7N9el+cssy7xVjhnlD9vMLGyDyFrbqjVv/JDlNefXvI3NiCIjsuntPFvDgYcZtX9mZjzXxmh+VqxVjubJ9N6WhtPbY+Y+ytcll7aV19qaSpvzb34mm+9p3/ZxlD8fm7W2cSP18FnK8s+bT2/XfNsbcTRdlqy1raf3U/s+a+53LN+2jTBPC5/L5ueTcPsvXrLq0I17guY9+M0sBj4JvA4YBn5kZg+4u4bKPIVFkREd/NNbRE5L3TgqeAnwC3d/0t2ngP8GXNuFcoiIlFI3gn85sKPt8XCYNoOZrTOzjWa2cWRkZN4KJyJSdN0I/tnaCw5pIXT32919jbuvWbp06TwUS0SkHLoR/MPAOW2PVwDPdKEcIiKl1I3g/xFwrpmtMrMq8BbggS6UQ0SklOa9V4+7N8zsvcDfk3fnvMvdt853OUREyqor/fjdfT2wvhvLFhEpOw3yIiJSMqfFWD1mNgI8fZxvXwKU8aoqZVzvMq4zlHO9y7jOcOzr/UJ3P6Rb5GkR/CfCzDbONkhR0ZVxvcu4zlDO9S7jOsPJW2819YiIlIyCX0SkZMoQ/Ld3uwBdUsb1LuM6QznXu4zrDCdpvQvfxi8iIjOVocYvIiJtFPwiIiVT6OA3syvN7P+Z2S/M7OZul6cTzOwcM3vIzLaZ2VYzuzFMX2Rm3zKz7eF2YbfLerKZWWxmPzGzr4fHq8zs0bDOfxfGgioUM1tgZl8xs5+Fff7qou9rM/vz8NneYmb3mFlPEfe1md1lZrvMbEvbtFn3reVuC9n2mJm98liWVdjgb7vS11XAy4C3mtnLuluqjmgA73f384G1wHvCet4MbHD3c4EN4XHR3Ahsa3v818DHwzo/D9zQlVJ11ieAB939pcBF5Otf2H1tZsuBPwPWuPuF5ON7vYVi7uvPA1ceNO1w+/Yq4Nzwtw749LEsqLDBT0mu9OXuO939x+H+KHkQLCdf17vDy+4GrutOCTvDzFYA1wB3hMcG/C7wlfCSIq7zEHAZcCeAu0+5+x4Kvq/JxxTrNbME6AN2UsB97e7fBZ47aPLh9u21wBc89wiwwMyWHe2yihz8R3WlryIxs5XAK4BHgbPcfSfkXw7Amd0rWUf8J+BfA+GS3CwG9rh7Izwu4v5+ETACfC40cd1hZv0UeF+7+6+BjwK/Ig/8vcAmir+vmw63b08o34oc/Ed1pa+iMLMB4F7gJnff1+3ydJKZ/VNgl7tvap88y0uLtr8T4JXAp939FcABCtSsM5vQpn0tsAo4G+gnb+Y4WNH29VxO6PNe5OAvzZW+zKxCHvpfcvevhsnPNn/6hdtd3SpfB1wKvN7MniJvwvtd8l8AC0JzABRzfw8Dw+7+aHj8FfIvgiLv698DfunuI+5eB74K/A7F39dNh9u3J5RvRQ7+UlzpK7Rt3wlsc/ePtT31AHB9uH89cP98l61T3P3fuvsKd19Jvl//t7u/DXgI+IPwskKtM4C7/wbYYWbnhUlXAI9T4H1N3sSz1sz6wme9uc6F3tdtDrdvHwD+eejdsxbY22wSOiruXtg/4Grg58ATwF90uzwdWsfXkP/EewzYHP6uJm/z3gBsD7eLul3WDq3/5cDXw/0XAT8EfgH8D6DW7fJ1YH1XAxvD/v6fwMKi72vgI8DPgC3AF4FaEfc1cA/5cYw6eY3+hsPtW/Kmnk+GbPspea+no16WhmwQESmZIjf1iIjILBT8IiIlo+AXESkZBb+ISMko+EVESkbBL9IBZnZ5c9RQkVONgl9EpGQU/FJqZvZ2M/uhmW02s78NY/zvN7NbzezHZrbBzJaG1642s0fC+Of3tY2N/hIz+7aZ/d/wnheH2Q+0jZ3/pXDmKWZ2i5k9Hubz0S6tupSYgl9Ky8zOB94MXOruq4EUeBv5QGA/dvdXAt8BPhTe8gXg37j7y8nPlmxO/xLwSXe/iHwcmeap868AbiK/HsSLgEvNbBHwBuCCMJ9/39m1FDmUgl/K7ArgYuBHZrY5PH4R+VDPfxde81+B15jZGcACd/9OmH43cJmZDQLL3f0+AHefcPex8Jofuvuwu2fkQ2msBPYBE8AdZvbPgOZrReaNgl/KzIC73X11+DvP3T88y+uONK7JbMPjNk223U+BxPMx5C8hH031OuDBYyyzyAlT8EuZbQD+wMzOhNb1TV9I/n/RHPnxj4Dvufte4Hkze22Y/g7gO55f+2DYzK4L86iZWd/hFhium3CGu68nbwZa3YkVEzmSZO6XiBSTuz9uZv8O+KaZReSjIr6H/AInF5jZJvIrPr05vOV64DMh2J8E3hWmvwP4WzP7yzCPPzzCYgeB+82sh/zXwp+f5NUSmZNG5xQ5iJntd/eBbpdDpFPU1CMiUjKq8YuIlIxq/CIiJaPgFxEpGQW/iEjJKPhFREpGwS8iUjL/Hw720pgWhiwoAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['mean_squared_error'], label='train')\n",
    "plt.plot(history.history['val_mean_squared_error'], label='train')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('MSE')\n",
    "plt.legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the plots showed, the epoch may be 10~20 is enough."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1470/1470 [==============================] - 0s 39us/sample - loss: 0.5384 - mean_squared_error: 0.5063\n",
      "MSE on test dataset: 0.50630826\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_mse = model.evaluate(x=xtest,y=ytest, steps=math.ceil(len(xtest)/32))\n",
    "print('MSE on test dataset:', test_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual value</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>827</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.595831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1083</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.150350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2495</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.108482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1655</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.323632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4403</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.494446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4189</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.107970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2280</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.895752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2633</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.445680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1035</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.871938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2574</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.794697</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1470 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      actual value  prediction\n",
       "827            9.0    6.595831\n",
       "1083           6.0    6.150350\n",
       "2495           5.0    6.108482\n",
       "1655           5.0    5.323632\n",
       "4403           5.0    5.494446\n",
       "...            ...         ...\n",
       "4189           5.0    5.107970\n",
       "2280           6.0    5.895752\n",
       "2633           5.0    5.445680\n",
       "1035           6.0    5.871938\n",
       "2574           5.0    5.794697\n",
       "\n",
       "[1470 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result=pd.DataFrame({'actual value':ytest})\n",
    "result['prediction'] = model.predict(xtest).reshape(1470,1)  #the original shape of np.array is (1, 1470).\n",
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
